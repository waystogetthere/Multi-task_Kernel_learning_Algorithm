{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 methods implemented here.\n",
    "\n",
    "1. Non-Kernel Stochastic Gradient Descent\n",
    "2. Kernel Stochastic Gradient Descent\n",
    "3. Kernel Batch Gradient Descent\n",
    "\n",
    "The training set are 20000 20D points which are  generated according to a normal distribution with mean = 0.0, std= 10.0\n",
    "The label set are generated according to a normal distribution with mean =0.0, std =5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iteration = 30000\n",
    "weight_decay = 0.01\n",
    "lr = 0.01\n",
    "NUM_EMPLOYEES = 500\n",
    "NUM_FEATURES = 20\n",
    "BANDWIDTH = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Training Set, Label Vector and Generate the Guassian Kernel according to the Training Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1.\n",
      " -1. -1.  1.  1.  1. -1.  1.  1. -1. -1. -1.  1. -1.  1. -1. -1.  1.  1.\n",
      " -1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1. -1. -1.  1. -1.  1.  1.\n",
      " -1. -1.  1. -1.  1. -1.  1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1. -1.\n",
      " -1.  1. -1. -1.  1. -1.  1. -1.  1.  1.  1. -1. -1. -1. -1.  1.  1.  1.\n",
      " -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1. -1.\n",
      " -1.  1. -1. -1.  1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      "  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  1.  1.  1.  1. -1. -1.  1.  1. -1.  1.  1. -1. -1.  1. -1. -1.  1.  1.\n",
      " -1. -1. -1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1. -1. -1. -1.  1.  1.\n",
      "  1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1.  1.  1.  1. -1.  1. -1.  1.\n",
      "  1. -1.  1. -1.  1. -1.  1.  1.  1.  1. -1. -1.  1. -1.  1.  1. -1. -1.\n",
      " -1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1. -1. -1.  1.  1. -1. -1.  1.\n",
      " -1. -1. -1. -1.  1.  1. -1.  1. -1. -1. -1.  1. -1.  1.  1. -1.  1. -1.\n",
      "  1. -1.  1.  1. -1. -1.  1.  1. -1.  1. -1.  1. -1.  1. -1. -1. -1.  1.\n",
      " -1. -1. -1. -1.  1. -1. -1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1. -1.\n",
      "  1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1. -1.  1. -1.  1. -1. -1. -1.\n",
      " -1. -1. -1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1. -1.  1. -1. -1. -1.\n",
      "  1. -1.  1. -1.  1.  1. -1.  1.  1. -1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
      "  1.  1.  1.  1. -1.  1.  1. -1. -1.  1.  1. -1.  1.  1. -1.  1.  1.  1.\n",
      " -1.  1.  1. -1.  1. -1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1. -1.  1.\n",
      "  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.\n",
      "  1. -1.  1. -1. -1. -1. -1. -1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.\n",
      " -1.  1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.  1.\n",
      "  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  1.  1. -1. -1.  1.\n",
      "  1.  1.  1. -1.  1. -1.  1.  1.  1. -1. -1. -1.  1.  1.  1.  1.  1.  1.\n",
      " -1.  1. -1.  1.  1. -1. -1. -1. -1.  1. -1.  1.  1.  1.]\n",
      "253\n",
      "[1.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 1.44505822e-297 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 3.22289967e-292 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 2.80909842e-245 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 1.48597403e-265 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000]\n"
     ]
    }
   ],
   "source": [
    "X = np.random.normal(loc=0.0, scale=10.0, size=(NUM_EMPLOYEES, NUM_FEATURES)) # the training set\n",
    "\n",
    "Y = np.random.normal(loc=0.0, scale=5.0, size=NUM_EMPLOYEES) # the Label Vector\n",
    "Y[Y > 0] = 1\n",
    "Y[Y < 0] = -1\n",
    "print(Y)\n",
    "print(np.sum(Y>0))\n",
    "# the BandWidth of Guassian Kernel.\n",
    "square = np.sum(X ** 2, axis=1)\n",
    "column_vec = square[:, np.newaxis]\n",
    "row_vec = square[np.newaxis, :]\n",
    "\n",
    "Gaussian_Kernel = np.exp(-1 * (-2 * X.dot(X.T) + column_vec + row_vec) / (2 * BANDWIDTH ** 2)) # the Gaussian Kernel \n",
    "print(Gaussian_Kernel[0,:])\n",
    "\n",
    "alpha = np.zeros(NUM_EMPLOYEES) # alpha recording the times that each sample has a non-zero loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-kernel Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.528\n"
     ]
    }
   ],
   "source": [
    "w = np.zeros(NUM_FEATURES)\n",
    "for t in range(max_iteration):\n",
    "    dw = np.zeros_like(w)\n",
    "    \n",
    "    index = int(np.random.rand() * NUM_EMPLOYEES)  # select one sample from training set randomly.\n",
    "    if 1 - Y[index] * X.dot(w)[index] > 0:\n",
    "        dw += -Y[index] * X[index]\n",
    "    w -= lr * dw\n",
    "print(np.sum(Y * X.dot(w) >= 1) / NUM_EMPLOYEES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "alpha = np.zeros(NUM_EMPLOYEES) # alpha recording the times that each sample has a non-zero loss\n",
    "# max_iteration = 10\n",
    "for t in range(max_iteration):\n",
    "    index = int(np.floor(np.random.rand() * NUM_EMPLOYEES)) # select one sample from training set randomly.\n",
    "    \n",
    "    if Y[index] * np.sum(alpha * Y * Gaussian_Kernel[index])/(weight_decay * (t+1))  < 1:\n",
    "        alpha[index] += 1\n",
    "        \n",
    "    if t % 5000 == 0:\n",
    "        y_predict = np.sum(alpha * Y * Gaussian_Kernel, axis=1)/(weight_decay * (t+1))\n",
    "        print(np.sum(y_predict * Y > 0) / NUM_EMPLOYEES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.982\n"
     ]
    }
   ],
   "source": [
    "print(alpha.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Gradient Descent is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.772\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.228\n"
     ]
    }
   ],
   "source": [
    "alpha = np.zeros(NUM_EMPLOYEES) \n",
    "for t in range(15):\n",
    "    y_predict = np.sum(alpha * Y * Gaussian_Kernel, axis=1) \n",
    "    result = y_predict * Y\n",
    "    indices = np.argwhere(result < 1)\n",
    "    alpha[indices] += 1\n",
    "\n",
    "    if t % 3 == 0:\n",
    "        y_predict = np.sum(alpha * Y * Gaussian_Kernel, axis=1)\n",
    "        print(np.sum(y_predict * Y >= 1) / NUM_EMPLOYEES)\n",
    "print(alpha.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
