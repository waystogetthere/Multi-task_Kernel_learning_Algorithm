{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy.linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the Hyper-Parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iteration = 10000\n",
    "weight_decay = 1e-5\n",
    "NUM_EMPLOYEES = 20500\n",
    "NUM_TRAIN = 20000\n",
    "NUM_VAL = 500\n",
    "Epsilon_1 = 10\n",
    "Epsilon_2 = 10 \n",
    "NUM_FEATURES = 3\n",
    "BANDWIDTH = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generating_Kernel(Feature_Matrix, Kernel_type, power=10, BW=10):\n",
    "    if Kernel_type == \"Gaussian_Kernel\":\n",
    "        square = np.sum(Feature_Matrix ** 2, axis=1)\n",
    "        column_vec = square[:, np.newaxis]\n",
    "        row_vec = square[np.newaxis, :]\n",
    "        Gaussian_Kernel = np.exp(-1 * (-2 * Feature_Matrix.dot(Feature_Matrix.T) + column_vec + row_vec) / (2 * BW ** 2))\n",
    "        return Gaussian_Kernel\n",
    "    elif Kernel_type == \"Linear_Kernel\":\n",
    "        return X.dot(X.T)\n",
    "    elif Kernel_type == \"Polynomial_Kernel\":\n",
    "        return (X.dot(X.T) + 1) ** power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.47657968 4.3703066  4.29534454] [-4.16416797 -4.20865582 -4.14432688]\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((NUM_EMPLOYEES, NUM_FEATURES))# the training set\n",
    "for i in range(NUM_EMPLOYEES):\n",
    "    while (True):\n",
    "        X[i] =np.random.multivariate_normal(np.zeros(NUM_FEATURES), np.eye(NUM_FEATURES))\n",
    "        _lambda = Epsilon_1 * np.sum(X[i,:] ** 2) + Epsilon_2 * np.sum(X[i,:])\n",
    "        if _lambda > 0:\n",
    "            break\n",
    "\n",
    "Mi = np.max(X, axis = 0)\n",
    "mi = np.min(X, axis = 0)\n",
    "print(Mi, mi)\n",
    "# X = (X - mi) / (Mi - mi)# rescale to [0, 1]\n",
    "\n",
    "survival_times = np.zeros(NUM_EMPLOYEES) # the surivial time of each employees\n",
    "for i in range(NUM_EMPLOYEES):\n",
    "    age = np.random.exponential(Epsilon_1 * np.sum(X[i,:] ** 2) + Epsilon_2 * np.sum(X[i,:]), size=1)\n",
    "    survival_times[i] = np.ceil(age)\n",
    "\n",
    "NUM_TASKS = int(max(survival_times))   \n",
    "\n",
    "Y = np.ones((NUM_EMPLOYEES, NUM_TASKS)) # the lifetime matrix of all employees, if one employee leave at the time interval k, then from Y[i,k](inlcude)  all entries are -1\n",
    "for i in range(NUM_EMPLOYEES):\n",
    "    Y[i, int(survival_times[i])-1:] = -1\n",
    "\n",
    "Kernel_Matrix = Generating_Kernel(X, \"Gaussian_Kernel\", BW = BANDWIDTH)\n",
    "Kernel_Matrix_Train = Kernel_Matrix[:NUM_TRAIN,:NUM_TRAIN]\n",
    "Kernel_Matrix_Val = Kernel_Matrix[NUM_TRAIN:,:NUM_TRAIN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(range(NUM_FEATURES), X[:,0], X[1], X[2])\n",
    "# plt.scatter(range(NUM_TRAIN), X[:NUM_TRAIN,0])\n",
    "# plt.scatter(range(NUM_TRAIN), X[:NUM_TRAIN,1])4\n",
    "for i in range(100):\n",
    "    plt.scatter(range(NUM_FEATURES), X[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largerthan035 = np.sum(X >= 0.35)\n",
    "largerthan064 = np.sum(X >= 0.64)\n",
    "print((largerthan035 - largerthan064) / (X.shape[0] * X.shape[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_vec = Kernel_Matrix_Train[0]\n",
    "mean_list = []\n",
    "median_list = []\n",
    "age_gap_list = []\n",
    "print(\"the age of 1st sample is:\", survival_times[0])\n",
    "for i in range(10):\n",
    "    indices = np.where((similarity_vec >= i*0.1) & (similarity_vec <= (i+1)*0.1)) [0]\n",
    "    age_gap = abs(survival_times[indices] - survival_times[0])\n",
    "    num_samples = len(indices)\n",
    "    print( \"There are \", num_samples , \"samples of similarity between {:.1f} and {:.1f}\".format(0.1 * i, 0.1 * (i+1)),\n",
    "          \"which have an average age_gap \",np.mean(age_gap), \n",
    "          \"and the median is:\",np.median(age_gap))\n",
    "    mean_list.append(np.mean(age_gap))\n",
    "    median_list.append(np.median(age_gap))\n",
    "    age_gap_list.append(age_gap)\n",
    "plt.boxplot(age_gap_list, patch_artist = True)\n",
    "plt.ylim(0,200)\n",
    "# plt.plot(np.linspace(0,1,10), mean_list)#, median_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a quick look at the distribution of ages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = np.arange(NUM_TASKS)+1\n",
    "y_train_gt_axis = np.zeros(NUM_TASKS)\n",
    "for i in range(NUM_TASKS):\n",
    "    y_train_gt_axis[i] = np.sum(survival_times[:NUM_TRAIN] == x_axis[i])\n",
    "plt.plot(x_axis, y_train_gt_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:NUM_TRAIN]\n",
    "X_val = X[NUM_TRAIN:]\n",
    "Y_train = Y[:NUM_TRAIN]\n",
    "Y_val = Y[NUM_TRAIN:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "print(Kernel_Matrix_Train[0].shape)\n",
    "print(Kernel_Matrix_Val[0])\n",
    "age_gap = abs(survival_times[:NUM_TRAIN] - survival_times[0])\n",
    "# print(survival_times - survival_times[0])\n",
    "plt.scatter(Kernel_Matrix_Train[0], age_gap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_pegasos(batch_size, Kernel_Matrix, alpha, Y_truth, loss_list, iter_times, weight_decay):\n",
    "    IDs = np.random.rand(batch_size,1) * NUM_TRAIN\n",
    "    IDs = IDs.astype(int).reshape(-1)\n",
    "    haty_IDs = (Kernel_Matrix[IDs].dot(alpha * Y_truth))  / (iter_times * weight_decay)\n",
    "    mask = Y_truth[IDs]*haty_IDs < 1\n",
    "    alpha[IDs] += mask\n",
    "    \n",
    "    '''\n",
    "\n",
    "    alpha_copy = alpha.copy()\n",
    "    alpha_copy[IDs] += mask\n",
    "    \n",
    "    W_product = (alpha_copy * Y_truth).T.dot(Kernel_Matrix.dot(alpha_copy * Y_truth))\n",
    "    loss = 0.5 * np.sum(W_product.diagonal())\n",
    "    hatY =  Kernel_Matrix.dot(alpha_copy * Y_truth) / ( iter_times * weight_decay)\n",
    "    mask1 = Y_truth*hatY <  0\n",
    "    loss += np.sum(abs((Y_truth*hatY))[mask1])\n",
    "    \n",
    "    if iter_times == 1 or loss < loss_list[-1]:\n",
    "        loss_list.append(loss)\n",
    "        # alpha = alpha_copy\n",
    "        alpha[IDs] += mask\n",
    "        # print(\"At iteration:\",t, \"the loss is,\", loss)\n",
    "        # print(alpha)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.zeros_like(Y_train) \n",
    "# alpha = np.ones_like(Y_train)\n",
    "predict_age = np.zeros(NUM_EMPLOYEES) \n",
    "val_loss_list = []\n",
    "index = 0\n",
    "for t in range(1, max_iteration+1):\n",
    "    # index = int(np.floor(np.random.rand()*NUM_TRAIN)) # randomly select one employee\n",
    "    # index \n",
    "    kernel_pegasos(5, Kernel_Matrix_Train, alpha, Y_train, val_loss_list, t, weight_decay)\n",
    "    # haty_index = (Kernel_Matrix_Train[index,:][np.newaxis,:].dot(alpha * Y_train)).reshape(-1) # calculate the predicted y vector\n",
    "    # haty_index /= t * weight_decay\n",
    "\n",
    "    ## update alpha\n",
    "\n",
    "    # mask = Y_train[index,:] * haty_index < 1\n",
    "    # alpha[index] += mask\n",
    "    # index += 1\n",
    "    # index = index%NUM_TRAIN\n",
    "    \n",
    "    if t%1000 == 0: # or t == 1:\n",
    "        print(\"the iteration is:\", t)\n",
    "        hatY_train = Kernel_Matrix_Train.dot(alpha*Y_train) / ( t * weight_decay )\n",
    "        \n",
    "        hatY_val =  Kernel_Matrix_Val.dot(alpha*Y_train) / ( t * weight_decay )\n",
    "        \n",
    "        for i in range(NUM_TRAIN):\n",
    "            predict_age[i] = np.where(hatY_train[i,:] < 0)[0][0] + 1\n",
    "\n",
    "        for i in range(NUM_TRAIN,NUM_EMPLOYEES):\n",
    "            predict_age[i] = np.where(hatY_val[i - NUM_TRAIN,:] < 0)[0][0] + 1\n",
    "            \n",
    "        acc_train = np.sum(Y_train * hatY_train > 0) / (NUM_TRAIN * NUM_TASKS)\n",
    "        acc_val = np.sum(Y_val * hatY_val > 0) / (NUM_VAL * NUM_TASKS)\n",
    "        print(\"the train accuracy is:\", acc_train)\n",
    "        print(\"the val accuracy is:\", acc_val)\n",
    "        \n",
    "        useful_pair = 0.0\n",
    "        denominator = NUM_VAL*(NUM_VAL-1)/2\n",
    "        \n",
    "        for i in range(NUM_TRAIN, NUM_EMPLOYEES):\n",
    "            for j in range(i+1, NUM_EMPLOYEES):\n",
    "                if (survival_times[i]-survival_times[j])*(predict_age[i]-predict_age[j])> 0: # useful pair\n",
    "                    useful_pair += 1\n",
    "                if  survival_times[i] == survival_times[j]: # two employees whose lifetime are identical\n",
    "                    denominator -= 1\n",
    "        \n",
    "        c_index = useful_pair / denominator\n",
    "        print(\"useful_pair\", useful_pair)\n",
    "        print(\"denominator\", denominator)\n",
    "        print(\"the c-index for VALIDATION is,\",c_index)\n",
    "        \n",
    "  \n",
    "print(np.sum(predict_age[NUM_TRAIN:] == survival_times[NUM_TRAIN:])/(NUM_VAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(survival_times[NUM_TRAIN:] - predict_age[NUM_TRAIN:] < 0))\n",
    "print(np.sum(survival_times[NUM_TRAIN:] - predict_age[NUM_TRAIN:] > 0))\n",
    "print(print(np.sum(survival_times[NUM_TRAIN:] - predict_age[NUM_TRAIN:] == 0)))\n",
    "print(survival_times[NUM_TRAIN:])\n",
    "print(predict_age[NUM_TRAIN:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = np.arange(NUM_TASKS)+1 # the x axis\n",
    "y_train_gt_axis = np.zeros(NUM_TASKS) # the ground truth train axis\n",
    "y_val_gt_axis = np.zeros(NUM_TASKS) # the groud truth validation axis \n",
    "y_train_predict_axis = np.zeros(NUM_TASKS) # the predict train axis \n",
    "y_val_predict_axis = np.zeros(NUM_TASKS) # the predict validation axis \n",
    "\n",
    "for i in range(NUM_TASKS):\n",
    "    y_train_gt_axis[i] = np.sum(survival_times[:NUM_TRAIN] == x_axis[i])\n",
    "    y_val_gt_axis[i] = np.sum(survival_times[NUM_TRAIN:] == x_axis[i])\n",
    "    y_train_predict_axis[i] = np.sum(predict_age[:NUM_TRAIN] == x_axis[i])\n",
    "    y_val_predict_axis[i] = np.sum(predict_age[NUM_TRAIN:] == x_axis[i])\n",
    "# plt.plot(x_axis, y_train_gt_axis, x_axis, y_train_predict_axis) # the training set: ground truth vs predict situation\n",
    "# plt.plot(x_axis, y_val_gt_axis, x_axis, y_val_predict_axis) # the valiadtion set: ground truth vs predictsituation\n",
    "plt.plot(x_axis, y_val_predict_axis)\n",
    "# plt.plot(x_axis,y_train_predict_axis,y_val_predict_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
